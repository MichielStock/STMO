{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Bracket search\n### Michiel Stock\n### 2019-2020"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "using Plots, LaTeXStrings\nusing STMO: myred, myblue, mygreen, myyellow, myorange,myblack"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "As a first introduction to mathematical optimization, we will study two *bracketing methods*. Bracketing methods can be used to minimize scalar function with a single input variable. These algorithms identify an interval $[a, b]$ containing the desired minimum. We will assume that the functions are *unimodal* they contain a single minimum.\n\n# Finding an initial bracket\n\nThe following function will generate from an initial $x$ an interval containing a local minimum. It works by moving one of the limits of the interval until the function value at that limit starts to decrease."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "function bracket_minimum(f, x=0.0; s=1e-2, k=2.0)\n  a, ya = x, f(x)  # lower limit of the interval\n  b, yb = x, f(x + s)  #  upper limit of the interval\n  if yb > ya  # default assumes f is decreasing in a, flip if not the case\n    a, b = b, a\n    ya, yb = yb, ya\n    s = -s  # go to the left instead of right\n  end\n  while true\n    c, yc = b + s, f(b + s)\n    if yc > yb\n      return a < c ? (a, c) : (c, a)\n    end\n    a, ya = b, yb\n    b, yb = c, yc\n    s *= k\n  end\nend"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "f(x) = 0.003x^4 + 8x^3 - 3x - 8\n\n(a, b) = bracket_minimum(f, k=1.2)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "plot(f, -0.5:0.01:0.5, xlabel=\"\\$ x\\$\", label=\"\\$ f(x) \\$\", color=myblue, lw=2)\nvline!([a, b], label=\"\", color=myorange, lw=2)\nvline!([0], label=\"\", color=mygreen, lw=2)\nxticks!([a, b, 0], [\"a\", \"b\", \"x\"])\nyticks!(:none)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bisection method\n\nThe bisection method is technically not a minimization algorithm, but a *root finding method*, i.e., it can be used to find an $x$ for a given function $g: \\mathbb{R}\\rightarrow \\mathbb{R}$ such that\n\n$$\ng(x) = 0\\,.\n$$\n\nWe can use the bisection method to find a minimum of a function $f(x)$ by finding points where the first derivative $f'(x)$ is equal to 0.\n\n> **Question**: in addition to the first derivative being equal to zero, which other criteria should hold for $x^\\star$ to be a minimizer?\n\nThe bisection method departs from an initial bracket $[a, b]$, where $g(a)$ and $g(b)$ have opposing signs. If $g(x)$ is a continious function, the *intermediate value theorem* states that there is at least one $x\\in[a,b]$ such that $g(x)$.\n\nIn every step of the bisection method, the interval it cut into half. The midpoint $x = (b-a)/2$ is computed, and a new bracket is formed from the midpoint and the side that contains zero."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "g(x) = tanh(sin(x))\n\na, b = -0.75, 1.2\n\nplot(g, -pi/2:0.1:pi/2, label=\"\\$g(x)\\$\", lw=2, color=myblue, xlabel=\"\\$ x\\$\", legend=:left)\nscatter!([a], [g(a)], color=myorange, label=:a)\nscatter!([b], [g(b)], color=mygreen, label=:b)\nvline!([(b+a)/2], color=myred, label=\"\\$x = (b-a)/2\\$\", lw=2)\nhline!([0], label=\"\", color=myblack, ls=:dash)\ntitle!(\"Illustration of the bisection method\")"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "The bisection procedure is repeated until the length of the interval is smaller than a small $\\epsilon > 0$. This $\\epsilon$ is called a *convergence parameter*, because it determines when the algorithm will halt. The pseudocode of the bisection method is given below.\n\n> **given** $g(x)$, the derivative of a function, initial interval $[a, b]$, tolerance $\\epsilon$.\n>\n> **while** $b - a > \\epsilon$\n>> 1. *Determine midpoint*. $x:=(a+b)/2$\n>> 2. *Update*.\n>>> **if $g(x)=0$**: $a:=x$, $b:=x$\n>>>\n>>> **else if $\\text{sign}(g(x)) = \\text{sign}(g(a))$**: $a:=x$\n>>>\n>>> **else**: $b:=x$\n>\n> **Output**: $[a, b]$\n\nSince every step shrinks the interval with a factor two, it is easy to show that this procedure stops within\n\n$$\n\\log_2\\left(\\frac{b-a}{\\epsilon}\\right)\n$$\n\niterations.\n\n**Assignment 1** Complete the code for the bisection method. Use it to find the minimum of\n\n$$\nf(x) = \\log(e^{8x-3}+2e^{0.2x^2-x+1})\n$$\n\nCheck your results graphically."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "function bisection(g, a, b; ϵ=1e-3)\n  @assert a < b \"a should be smaller than b\"\n\n  # a is minizer?\n  g(a) == 0 && return a, a\n  # b is minizer?\n  g(b) == 0 && return b, b\n\n  while ...\n    ...\n  end\n  return a, b\nend"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "f(x) = log(exp(8x-3)+2exp(0.2x^2-x+1))"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "> To type `f′` just type `f\\prime<tab>`. Whenever you are unsure how to type a unicode character you can call it using the help, e.g. `?ϵ`."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "f′(x) = ..."
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Quadratic fit search\n\nAs we will see in the next lecture, finding the minimum of quadratic functions of the form\n\n$$\nq(x) = p_1 + p_2 x + p_3 x^2\n$$\n\nis trivial. The *quadratic fit search method* will approximate a function by a quadratic function and computes the minimizer of that function.\n\nGiven three bracketing points $a<b<c$ and their respective evaluations $y_a=f(a), y_b=f(b)$ and $y_c=f(c)$, we can fit a quadratic curve by solving the following system of equations for the coefficients:\n\n$$\n\\begin{bmatrix}y_a\\\\ y_b \\\\ y_c\\end{bmatrix} = \\begin{bmatrix}1 & a & a^2 \\\\ 1 & b & b^2 \\\\ 1 & c & c^2 \\end{bmatrix} \\begin{bmatrix}p_1\\\\ p_2 \\\\ p_3\\end{bmatrix}\\,.\n$$\n\nFor example, in Julia, we have:"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "a, b, c = -2, -1, 3\nya, yb, yc = f.([a, b, c])\n\np1, p2, p3 = [1 a a^2; 1 b b^2; 1 c c^2] \\ [ya, yb, yc]"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can even dispense solving the system and use a closed-form fit based on three points:\n\n$$\nq(x) = y_a\\frac{(x-b)(x-c)}{(a-b)(a-c)} +  y_b\\frac{(x-a)(x-c)}{(b-a)(b-c)}+ y_c\\frac{(x-a)(x-b)}{(c-a)(c-b)}\\,.\n$$\n\nThe unique minimum of this quadratic curve is computed by:\n\n$$\nx^\\star = \\frac{1}{2} \\frac{y_a(b^2-c^2) + y_b(c^2-a^2)+ y_c(a^2-b^2)}{y_a(b-c) + y_b(c-a)+ y_c(a-b)}\\,.\n$$\n\nWe have implemented these two formulas in `quadratic_fit` and `quadratic_fit_min`. See below for an illustration."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "function quadratic_fit(a, b, c, ya, yb, yc)\n  @assert a != b != c\n  return x -> ya * (x-b) * (x-c) / ((a-b) * (a-c)) +\n              yb * (x-a) * (x-c) / ((b-a) * (b-c)) +\n              yc * (x-a) * (x-b) / ((c-a) * (c-b))\nend\n\nfunction quadratic_fit_min(a, b, c, ya, yb, yc)\n  return 0.5 * (ya * (b^2 - c^2) + yb * (c^2 - a^2) + yc * (a^2 - b^2)) /\n        (ya * (b-c) + yb * (c-a) + yc * (a-b))\nend"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "x = quadratic_fit_min(a, b, c, ya, yb, yc)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "plot(f, -3:0.1:5, label=\"\\$f(x)\\$\", lw=2, xlabel=\"\\$x\\$\", color=myblue)\nscatter!([a, b, c], [ya, yb, yc], label=\"\\$a, b, c\\$\", color=myorange)\nplot!(quadratic_fit(a, b, c, ya, yb, yc), -3:0.1:5, label=\"\\$ q(x) \\$\", lw=2, color=mygreen)\nvline!([x], label=\"\\$x\\$\", lw=2, color=myred)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Given the minimizer $x^\\star$ of the quadratic approximation, we can update the interval closer to this value. The quadratic fit search repeats this approach $n$ times. The pseudocode is given below.\n\n> **given** $f(x)$, the function to be minimized, three increasing values $a, b, c$ with $f(a) > f(b)$ and $f(c) > f(b)$, the number of steps $n$.\n>\n> **repeat** $n$ times\n>> 1. *Fit quadratic*\n>> 2. *Determine minimizer of $q(x)$*\n>> 3. *Update bracket*:\n>>> **if $x\\in [a,b]$**: $a, b, c := a, x, b$\n>>> **else**: $a, b, c := b, x, c$\n>\n> **Output**: $a, b, c$\n\n**Assignment 2** Complete the code for the quadratic fit search method. Use it again to find the minimizer of the provided $f(x)$."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "function quadratic_fit_search(f, a, b, c, n)\n  @assert a < b < c \"a, b, c not consecutive \"\n  @assert f(a) > f(b) && f(c) > f(b) \"f(b) should be less than f(a) and f(c)\"\n\n  for i in 1:n\n    ...\n    ...\n  end\n  return a, b, c\nend"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "The coming chapters will discuss the minimization of quadratic functions in much greater detail.\n\n# Exercises\n\n1. Find the maximum of $\\sqrt[\\leftroot{-2}\\uproot{2}x]{x}$.\n2. Given a chemical system for which a chemical with concentration is degraded by enzymic conversion and chemical decay. The rate of removal is given by\n$$\nr(x) = 0.02 + 1.2\\frac{x}{10+x}\\,.\n$$\nThe system receives a constant input with a concentration of 0.3. What is the steady-state concentration?"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# References\n\n- Kochenderfer, M. J. and Wheeler, T., '*Algorithms for Optimization*'. MIT Press (2019)"
      ],
      "metadata": {}
    }
  ],
  "nbformat_minor": 2,
  "metadata": {
    "language_info": {
      "file_extension": ".jl",
      "mimetype": "application/julia",
      "name": "julia",
      "version": "1.3.1"
    },
    "kernelspec": {
      "name": "julia-1.3",
      "display_name": "Julia 1.3.1",
      "language": "julia"
    }
  },
  "nbformat": 4
}
