{
  "cells": [
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "using Plots\nusing LinearAlgebra\nusing STMO\nimport STMO.Quadratic: plot_quadratic, fquad"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Motivation\n\nQuadratic systems are essential! Firstly, we can often closely approximate systems close to their maximum by a quadratic system. Studying the minimization of quadratic systems can teach us about the minimization of general convex functions. Quadratic systems are also crucial in their own right! Many statistical models, graph problems, molecular models, etc. can be formulated as quadratic systems:\n\n- least-square minimization problems\n- inference using multivariate normal distributions\n- molecular modeling using spring-mass systems\n- signal recovery\n\n# Warming up: one-dimensional quadratic systems\n\nIn the scalar case, a quadratic function is given by\n\n$$\nf(x) = \\frac{1}{2}px^2+qx +r\\,,\n$$\n\nwith $p>0$ (we will shortly see why).\n\nOur optimization problem is given by:\n\n$$\n\\min_x\\,\\frac{1}{2}px^2+qx +r\\,.\n$$\n\nThis can easily be solved by setting the first order derivative equal to zero:\n\n$$\n\\frac{\\mathrm{d}f(x)}{\\mathrm{d}x} = px + q\n$$\n$$\npx^\\star+q = 0 \\Leftrightarrow x^\\star=\\frac{-q}{p}\\,.\n$$\n\nTo show that this is the sole minimizer of $f(x)$, we have to prove that the second-order derivative is positive at this point. This means that at that point, the derivative of the function is increasing: a little to the left the function is increasing, a little to the right and the function is decreasing. We have\n$$\n\\left.\\frac{\\mathrm{d}^2f(x)}{\\mathrm{d}x^2}\\right|_{x^\\star} = p\\,,\n$$\nso if $p>0$ then $x^\\star$ is the minimizer of $f(x)$.\n\n\n**Assignment 1**\nComplete the code for solving the 1-D quadratic system. Use it to find the minimum of\n$$\n4x^2+8x + 2\\,.\n$$\nCheck the solution graphically."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "\"\"\"\n    solve_quadratic(p::Real, q::Real, r::Real=0.0)\n\nFinds the minimizer of a 1-D quadratic system,\nraises an error if there is no minimizer (p<0)\n\nInputs:\n    - p, q, r: the coefficients of the 1D quadratic system\n\nOutput:\n    - xstar: the minimizer\n\"\"\"\nfunction solve_quadratic(p::Real, q::Real, r::Real=0.0)\n    @assert ...\n    return ...\nend"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "p = ...\nq = ...\nr = ...\n\n# solve the system"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "# plot the system and the solution"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Towards $n$-dimensional quadratic systems\n\nLet us directly move from the one-dimensional case to the $n$-dimensional case. We will use vector notation:\n$$\n\\mathbf{x} = \\begin{bmatrix}\n       x_1 \\\\ \\vdots \\\\ x_n\n     \\end{bmatrix} \\in \\mathbb{R}^n\\,.\n$$\nA general $n$-dimensional linear system is given by:\n$$\nf(\\mathbf{x}) =\\frac{1}{2} \\mathbf{x}^\\top P \\mathbf{x} + \\mathbf{q}^\\top\\mathbf{x} + r\\,,\n$$\nwith $P$ an $n\\times n$ symmetric matrix, $\\mathbf{q}$ an $n$-dimensional vector and $r$ a scalar. Below, the contours of a two-dimensional example are shown."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "P = [4 1; 1 2]\nq = [-1; 1]\nr = -10\n\nplot_quadratic(P, q, r, (-10, 10), (-10, 10), fill=true)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 1**\nWhy is $P$ symmetric?\n\nSo we want to solve the problem:\n$$\n\\min_\\mathbf{x}\\,\\frac{1}{2}\\mathbf{x}^\\top P \\mathbf{x} + \\mathbf{q}^\\top\\mathbf{x} + r\\,.\n$$\n\nThe concept of a derivative is extended towards higher dimensions using the *gradient* operator:\n$$\n\\nabla_\\mathbf{x} = \\begin{bmatrix}\n       \\frac{\\partial \\, }{\\partial x_1} \\\\ \\vdots \\\\ \\frac{\\partial \\, }{\\partial x_n}\n     \\end{bmatrix}\\,,\n$$\nso that the gradient of $f(\\mathbf{x})$ is given by:\n$$\n\\nabla_\\mathbf{x} f(\\mathbf{x}) = \\begin{bmatrix}\n       \\frac{\\partial f(\\mathbf{x}) }{\\partial x_1} \\\\ \\vdots \\\\ \\frac{\\partial f(\\mathbf{x}) }{\\partial x_n}\n     \\end{bmatrix}\\,.\n$$\nFrom now on, we will drop the subscript in the gradient when clear from context. For those not familiar to vector calculus, the most useful rules are given below. Here, $a, b$ and $c$ are scalars, $f$ and $g$ are arbitrary differentiable functions and $\\mathbf{b}$ is a vector.\n\n| rule | example                  |\n| :------------- | :------------- |\n| linearity      | $\\nabla_\\mathbf{x}(a f(\\mathbf{x}) +b g(\\mathbf{x})) = a\\nabla_\\mathbf{x} f(\\mathbf{x}) +b\\nabla_\\mathbf{x} g(\\mathbf{x})$       |\n| product rule | $\\nabla_\\mathbf{x}(f(\\mathbf{x}) g(\\mathbf{x})) = g(\\mathbf{x})\\nabla_\\mathbf{x} f(\\mathbf{x}) + f(\\mathbf{x})\\nabla_\\mathbf{x} g(\\mathbf{x})$|\n|chain rule | $\\nabla_{\\mathbf{x}} f(g(\\mathbf{x})) = \\frac{\\partial f}{\\partial g}\\mid_{g(\\mathbf{x})} \\nabla_\\mathbf{x} f(\\mathbf{x})$|\n| quadratic term | $\\nabla_\\mathbf{x} \\left(\\frac{1}{2}\\mathbf{x}^\\top A\\mathbf{x}\\right)= A\\mathbf{x}$|\n|linear term| $\\nabla_\\mathbf{x} (\\mathbf{b}^\\top\\mathbf{x})=\\mathbf{b}$|\n|constant term |$\\nabla_\\mathbf{x} c = 0$ |\n\nw\n\nThe gradient of the quadratic function is\n$$\n\\nabla f(\\mathbf{x})=P\\mathbf{x} +\\mathbf{q}\\,.\n$$\nSetting this to zero gives\n$$\n\\mathbf{x}^\\star=-P^{-1}\\mathbf{q}\\,.\n$$\n\n> *Even though the solution contains the inverse of a matrix, it is seldom a good idea to compute a matrix inverse. Instead, use a solver for the linear system $A\\mathbf{x}=\\mathbf{b}$ (numerically stable).*\n\nHow do we know that $\\mathbf{x}^\\star$ is the minimizer of the quadratic system? For this we have to extend the concept of a second order derivative to $n$ dimensions. We define the *Hessian* as:\n$$\n\\nabla^2 f(\\mathbf{x}) = \\begin{bmatrix}\n\\frac{\\partial^2 f(\\mathbf{x})}{\\partial {x_{1}^2}} & \\frac{\\partial^2 f(\\mathbf{x})}{\\partial x_1 x_2} & \\ldots &  \\frac{\\partial^2 f(\\mathbf{x})}{\\partial x_1 x_n}\\\\\n\\frac{\\partial^2 f(\\mathbf{x})}{\\partial x_1 x_2} & \\frac{\\partial^2 f(\\mathbf{x})}{\\partial {x_2}^2} & \\ldots & \\vdots \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\n\\frac{\\partial^2 f(\\mathbf{x})}{\\partial x_1 x_n} & \\frac{\\partial^2 f(\\mathbf{x})}{\\partial x_2 x_n} & \\ldots & \\frac{\\partial^2 f(\\mathbf{x})}{\\partial x_n^2}\n\\end{bmatrix}\\,.\n$$\nFor the quadratic system, this boils down to\n$$\n\\nabla^2 f(\\mathbf{x}) = P\\,.\n$$\nThe condition for $\\mathbf{x}^\\star$ to be the minimizer of $f(\\mathbf{x})$ is that the Hessian should be *positive-definite* in that point.\n\n> A symmetric $n\\times n$ matrix $A$ is positive-definite (in symbols: $A\\succ0$), if for any vector $\\mathbf{z}\\in\\mathbb{R}^n$\n> $$\n> \\mathbf{z}^\\top A \\mathbf{z} > 0\\,.\n> $$\n\nA matrix is positive-definite if (and only if) all its eigenvalues as positive. In Julia, we can easily check whether a matrix is positive-define using `isposdef`:"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "using LinearAlgebra\n\nA = [5 -1; -1 2]\nisposdef(A)  # true"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "B = [0.5 3; 3 1]\nisposdef(B)  # false"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "However, this is an expensive operation (it is based on attempting a Cholesky decomposition), so one should avoid performing unnecessary checks for positive definiteness.\n\nA point $\\mathbf{x}^\\star$ at which the gradient vanishes is a minimizer if and only if\n$$\n\\nabla^2 f(\\mathbf{x})|_{\\mathbf{x}^\\star} \\succ 0\\,.\n$$\n\nSo, for the quadratic problem, $x^\\star$ is the unique minimizer iff $P\\succ 0$. This means that along every direction $\\mathbf{v}\\in \\mathbb{R}^n$ to project $\\mathbf{x}$, the problem reduces to a one-dimensional quadratic function with a positive second-order constant:\n$$\nx_v = \\mathbf{v}^\\top \\mathbf{x}\\\\\nf'(x_v) = \\frac{1}{2}x_v (\\mathbf{v}^\\top P \\mathbf{v}) x_v + (\\mathbf{v}^\\top \\mathbf{q})x_v + r\\,,\n$$\nwhere $\\mathbf{v}^\\top P \\mathbf{v}>0$ if $P\\succ 0$, which in turn implies that $f'(x_v)$ has a minimizer.\n\nIf $P\\succ 0$, the quadratic system is a *convex* function with a single minimizer. In many problems, $P$ is positive-definite, so there is a well-defined solution. We will develop this further in Chapter 2.\n\n**Assignment 2**\n\nComplete the code for solving the $n$-D quadratic system. Use it to find the minimum of\n$$\nf(\\mathbf{x}) = \\mathbf{x}^\\top\\begin{bmatrix}4 & 1 \\\\ 1 & 2\\end{bmatrix}\\mathbf{x} + \\begin{bmatrix}3 \\\\ 1\\end{bmatrix}^\\top\\mathbf{x} + 12\\,.\n$$"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "\"\"\"\n    solve_quadratic(P::AbstractMatrix, q::AbstractVector, r::Real=0)\n\nFinds the minimizer of an N-D quadratic system.\nP is assumed to be a symmetric and positive-definite matrix.\n\nInputs:\n    - P, q, r: the terms of the nD quadratic system\n\nOutput:\n    - xstar: the minimizer, an (n x 1) vector\n\"\"\"\nfunction solve_quadratic(P::AbstractMatrix, q::AbstractVector, r::Real=0.0)\n    return ...\nend"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "P = ...\nq = ...\nr = ...\n# compute the minimizer"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 2**\n\nConsider $L_2$ regularized ridge regression:\n$$\n\\min_\\mathbf{x}\\, \\frac{1}{2}(\\mathbf{y} - B\\mathbf{x})^\\top(\\mathbf{y} - B\\mathbf{x}) + \\frac{c}{2}\\cdot \\mathbf{x}^\\top\\mathbf{x}\\,,\n$$\nwith $c>0$. Write this in the standard form of a quadratic system and show that it is convex. Give the expression for the minimizer.\n\n# Time and memory complexity of the exact solution\n\nThe exact solution for a convex quadratic system hinges on solving a $n\\times n$ linear system. Conventional solvers for linear systems have a time complexity of $\\mathcal{O}(n^3)$. Solving such systems is doable for problems of moderate size ($n<10000$), but becomes infeasible for large-scale problems (on a standard computer)."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "solvetime = Float64[]\ninvtime = Float64[]\nsizes = [2, 5, 10, 50, 100, 500, 1000, 5000, 10000]\n\nP = randn(2, 2)\nq = randn(2)\n\n# warmup\n@elapsed(P \\ q)\n@elapsed(inv(P) * q)\n\nfor n in sizes\n    P = randn(n, n) |> x -> x' * x + I\n    q = randn(n)\n    push!(solvetime, @elapsed(P \\ q))\n    push!(invtime, @elapsed(inv(P) * q))\nend\n\nplot(sizes, solvetime, color=myblue, label=\"time for solving\", lw=2, xscale=:log10,\n                            yscale=:log10)\nplot!(sizes, invtime, color=myred, label=\"time for inverting P\", lw=2)\nxlabel!(\"n\")\nylabel!(\"seconds\")"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Storing an $n\\times n$ matrix also has a memory requirement of $\\mathcal{O}(n^2)$. When $n$ is too large, this cannot fit in main memory. In the remainder of this chapter, we will consider the case when $P$ is too large to work with, while matrix-vector products $P\\mathbf{x}$ *can* be computed. Some examples of when such settings occur:\n\n- **low-rank**: $P=B^\\top B$, with $B\\in \\mathbb{R}^{n\\times p}$, with $p\\ll n$.\n- **sparse**: $P$ is a very sparse matrix.\n- **structured**: $P$ has a special structure so that $P\\mathbf{x}$ can be computed on the fly, e.g. $P_{ij}=i^2j^3$.\n- **block**: $P$ is a sparse block matrix (blocks can be loaded and processed independently).\n\n# Descent methods\n\nInstead of computing the solution of a convex quadratic system in one step, we will use *descent methods*. Here, a minimizing sequence $\\mathbf{x}^{(k)},\\, k=1,\\dots$, where\n$$\n\\mathbf{x}^{(k+1)} = \\mathbf{x}^{(k)} +t^{(k)}\\Delta \\mathbf{x}^{(k)}\\,,\n$$\nwith $t^{(k)}\\geq 0$ called the *step size* (in machine learning often called *learning rate*) and $\\Delta \\mathbf{x}^{(k)}$ called the *search direction*. Proper descent methods have that\n$$\nf(\\mathbf{x}^{(k+1)}) < f(\\mathbf{x}^{(k)})\\,,\n$$\nexcept when $\\mathbf{x}^{(k)}$ is optimal. For this property to hold, the search direction should satisfy\n$$\n(\\Delta \\mathbf{x}^{(k)})^\\top \\nabla f(\\mathbf{x}) < 0\\,.\n$$\n\n![Descent and ascent step.](Figures/descent_step.png)\n\n## General descent algorithm\n\nBelow is the general pseudocode of a general descent method:\n\n> **given** a starting point $\\mathbf{x}$\n>\n> **repeat**\n>> 1. Determine descent direction $\\Delta \\mathbf{x}$\n>> 2. *Line search*. Choose $t>0$.\n>> 3. *Update*. $\\mathbf{x}:=\\mathbf{x} + t \\Delta \\mathbf{x}$.\n>\n> **until** stopping criterion is reached.\n>\n> **Output**: $\\mathbf{x}$\n\nUsually, the convergence criterion is of the form\n$$\n||\\nabla f(\\mathbf{x})|| < \\nu\\,.\n$$\n\nThe step size can be chosen in several ways:\n\n- **exact**: $t=\\arg\\min_{s\\geq 0}\\, f(\\mathbf{x}+s\\Delta \\mathbf{x})$.\n- **approximate**: choose a $t$ that only approximately minimizes $f(\\mathbf{x}+s\\Delta \\mathbf{x})$.\n- **decaying**: choose some decaying series, e.g. $t = \\frac{1}{\\alpha+k}$.\n- **constant**: a constant step size (often works fine in practice).\n\nFor quadratic systems we can compute the exact step size, as this amounts to a simple one-dimensional quadratic problem:\n$$\nt=\\arg\\min_{s\\geq 0}\\, \\frac{1}{2}(\\mathbf{x}+s\\Delta \\mathbf{x})^\\top P (\\mathbf{x}+s\\Delta \\mathbf{x}) + (\\mathbf{x}+s\\Delta \\mathbf{x})^\\top \\mathbf{q} + r\n$$\n$$\n =\\arg\\min_{s\\geq 0}\\, \\frac{1}{2}s^2(\\Delta\\mathbf{x})^\\top P \\Delta\\mathbf{x} + s((\\Delta \\mathbf{x})^\\top P\\mathbf{x}+(\\Delta \\mathbf{x})^\\top\\mathbf{q}) +\\text{constant}\n$$\n\nThis can be solved as:\n\n$$\nt = \\frac{-(\\Delta\\mathbf{x})^\\top P \\mathbf{x}-(\\Delta\\mathbf{x})^\\top\\mathbf{q}}{(\\Delta\\mathbf{x})^\\top P \\Delta\\mathbf{x}}\n$$\n\n**Assignment 3**\n\nComplete the code for the exact line search for quadratic systems."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "\"\"\"\n    quadratic_ls(P::AbstractMatrix, q::AbstractVector, Δx::AbstractVector,\n                                    x::AbstractVector)\n\nFind the exact step size that minimized a quadratic system in\na given point x for a given search direction Dx\n\nInputs:\n    - P, q: the terms of the nD quadratic system\n    - x: starting point\n    - Δx: search direction\n\nOutput:\n    - t: optimal step size\n\"\"\"\nfunction quadratic_ls(P::AbstractMatrix, q::AbstractVector, Δx::AbstractVector,\n                                    x::AbstractVector)\n    ...  # compute t\n    return t\nend"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gradient descent\n\nA natural choice for the search direction is the negative gradient:\n$$\n\\Delta \\mathbf{x} = - \\nabla f(\\mathbf{x})\\,.\n$$\nRemember, for the quadratic system, the gradient was\n$$\n\\nabla f(\\mathbf{x})=P\\mathbf{x} + \\mathbf{q}\\,,\n$$\nso\n$$\n\\Delta \\mathbf{x} = - P\\mathbf{x} - \\mathbf{q}\\,.\n$$\n\n## Gradient descent algorithm for quadratic systems\n\n> **given** a starting point $\\mathbf{x}$\n>\n> **repeat**\n>> 1. *Descent direction*. $\\Delta \\mathbf{x} := - P\\mathbf{x} - \\mathbf{q}$\n>> 2. *Line search*. Choose optimal $t>0$.\n>> 3. *Update*. $\\mathbf{x}:=\\mathbf{x} + t \\Delta \\mathbf{x}$.\n>\n> **until** stopping criterion is reached.\n\n**Assignment 4**\n\nComplete the code for the gradient descent algorithm. Solve the previous quadratic system and compare it with the analytic solution. Start at $\\mathbf{x}^{(0)}=[0,0]^\\top$. How many steps do you need for the algorithm to converge? You can access this information from a `Tracker` structure using the function `length`."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "\"\"\"\n    gradient_descent(P::AbstractArray, q::AbstractVector,\n            x₀::AbstractVector; ϵ::Real=1e-6,\n            tracker::Tracker=notrack)\n\nComputes the minimizes of a quadratic system using gradient descent. Optionally\nprovide momentum.\n\nInputs:\n    - P, q: the terms of the nD quadratic system\n    - x₀: starting point\n    - ϵ: convergence parameter\n    - tracker: object of the type `Tracker` to save the steps\n\nOutputs:\n    - xstar: the found minimum\n\"\"\"\nfunction gradient_descent(P::AbstractArray, q::AbstractVector,\n            x₀::AbstractVector; ϵ::Real=1e-4, trace=False):\n\n    x = x0  # initial value\n    n_steps = 0\n    while true\n        Dx = ...  # compute GD direction\n        if ...\n            break\n        end\n        t = ...  # step size\n        ...  # perform step\n        trace(tracker, x)\n    end\n    return x\n  end"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "# solve the quadratic system using gradient descent"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Illustration\n\nWe illustrate the gradient descent algorithm for the following system:\n$$\n\\min_{x_1,x_2}\\, \\frac{1}{2} (x_1^2 + \\gamma x_2^2)\\,\n$$\nwith $\\gamma$ set to 10."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "#using STMO: plotobj, fquad, plot_quadratic\n#using STMO: PathTrack\n\nP = [1 0; 0 10]\nq = [0, 0]\nr = 0\nx₀ = [10.0, 1.0]\n\ngdtracker = PathTrack(x₀)\n\nxstar = Quadratic.gradient_descent(P, q, copy(x₀), tracker=gdtracker)\n\np1 = plotobj(x -> fquad(x, P, q, r), gdtracker, yscale=:log10, label=\"GD\",\n    ylabel=\"f(x) - f(x*)\");\np2 = plot_quadratic(P, q, r, (-10, 10), (-5, 5));\npath!(gdtracker, label=\"GD\");\nplot(p1, p2)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convergence analysis\n\nWe can study the convergence of the gradient descent algorithm by using eigenvalue decomposition. The matrix $P$ can be written as:\n$$\nP = U\\Lambda U^\\top\\,,\n$$\n\nwith\n\n-  $\\Lambda=\\text{diag}(\\lambda_1,\\ldots,\\lambda_n)$ a matrix with the eigenvalues on the diagonal (sorted from small to large);\n-  $U = [\\mathbf{u}_1, \\ldots, \\mathbf{u}_n]$, a matrix with the corresponding eigenvectors.\n\nNote that because $P\\succ 0$, all eigenvalues are real and positive, and all eigenvectors form a real orthonormal basis.\n\nConsider the following linear transformation:\n$$\n\\mathbf{z}^{(k)}= U^\\top ( \\mathbf{x}^{\\star}-\\mathbf{x}^{(k)})\\,,\n$$\n\nwhich allows us to rewrite the error in closed-form:\n\n$$\nf(\\mathbf{x}^{(k)}) - f(\\mathbf{x}^\\star) = \\frac{1}{2}\\sum_{i=1}^n (1-t\\lambda_i)^{2k}\\lambda_i[(\\mathbf{u}_i)^\\top(\\mathbf{x}^{(0)}-\\mathbf{x}^\\star)]^2\\,.\n$$\n\nHere, we see that:\n\n1. The error decomposes in independent terms in the eigenspace.\n2. The convergence of each term is determined by the *rate*: $|1-t\\lambda_i|$. Convergence occurs as a geometric series.\n3. The total number of steps until convergence is determined by either the smallest and largest eigenvalue.\n4. Optimal value for fixed step size is $t=\\frac{1}{\\lambda_1+\\lambda_n}$."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "using Plots, STMO\nλs = [0.1, 1.5, 1.6, 1.8, 2]\n\nx₀ = ones(5)\nt = 2 / (maximum(λs) + minimum(λs))\n# error xstar = 0, x₀ = 1\nerrors = [(1.0 - t * λ)^(2k) * λ * x₀ᵢ^2 for k in 0:1000, (λ, x₀ᵢ) in zip(λs, x₀)]\ncumerrors = cumsum(errors, dims=2)\nplot(cumerrors[:,1], fillrange=0, xscale=:log10, color=myblue, fillcolor=myblue, label=\"lam 1 = $(λs[1])\")\nplot!(cumerrors[:,2], fillrange=cumerrors[:,1], color=myred, fillcolor=myred, label=\"lam 2 = $(λs[2])\")\nplot!(cumerrors[:,3], fillrange=cumerrors[:,2], color=mygreen, fillcolor=mygreen, label=\"lam 3 = $(λs[3])\")\nplot!(cumerrors[:,4], fillrange=cumerrors[:,3], color=myorange, fillcolor=myorange, label=\"lam 4 = $(λs[4])\")\nplot!(cumerrors[:,5], fillrange=cumerrors[:,4], color=myyellow, fillcolor=myyellow, label=\"lam 5 = $(λs[5])\")\nxlabel!(\"k+1\")\nylabel!(\"f(x) - f(x*)\")\ntitle!(\"Error of gradient descent\\n(cumulative eigencomponents)\")"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "plot(errors, ylims=(1e-15,7), lw=2, xscale=:log10, yscale=:log10,\n             color = [myblue myred myorange mygreen myyellow],\n             label=[\" lambda  $i = $(λs[i])\" for j in 1:1, i in 1:5])\nxlabel!(\"k+1\")\nylabel!(\"f(x) - f(x*)\")\ntitle!(\"Error of gradient descent\\n(individual contributions)\")"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Furthermore, it can be shown that if we use an exact line search for the step size, the error $f(\\mathbf{x}^{(k)}) - f(\\mathbf{x}^\\star)\\leq \\epsilon$ we need fewer than\n$$\n\\frac{\\log((f(\\mathbf{x}^{(0)}) - f(\\mathbf{x}^\\star))/\\epsilon)}{\\log(1/c)}\\,,\n$$\nwith $c=1-\\frac{\\lambda_1}{\\lambda_n}<1$. The quantity $\\kappa=\\frac{\\lambda_n}{\\lambda_1}$ is called the *condition number* and largely determines the convergence. We observe:\n\n- The quality of the initial guess $f(\\mathbf{x}^{(k)}) - f(\\mathbf{x}^\\star$) has only a logarithmic impact on the number of steps required.\n- Only a few extra steps are needed to decrease $\\epsilon$ with one order of magnitude.\n- If the condition number is large, then $\\log(1/c)\\approx 1/\\kappa$. Large condition numbers require more steps.\n\nBelow, we illustrate this bound for different condition numbers."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "κs = [1.1, 2.5, 5, 50, 100]\n\nbestt(κ) = 2 / (1 + κ)\nerrors = [(1 - bestt(κ))^(2k) + (1-bestt(κ) * κ)^(2k) * κ for k in 1:10000, κ in κs]\n\nplot(errors, color = reshape(mycolors, 1, :),\n        labels = [\" kappa = $κ\" for i in 1:1, κ in κs],\n        xscale=:log10, yscale=:log10, ylims=(1e-10, 100), lw=2)\n\nκ2c(κ) = 1 - 1 / κ\nbounds = [exp(log(1+κ) - k * log(1/κ2c(κ))) for k in 1:10000, κ in κs]\n\nplot!(bounds, lw=2, ls=:dash, color = reshape(mycolors, 1, :), label=\"\")\nylabel!(\"f(x) - f(x*)\")\nxlabel!(\"k + 1\")\ntitle!(\"Convergence (-) and bound (--) of GD\\n for different condition numbers\")"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gradient descent with momentum\n\n> *While finding the gradient of an objective function is a splendid idea, [descending] the gradient directly may not be.* ~ David J.C. MacKay\n\nEven on simple quadratic problems as discussed here, gradient descent often takes a surprisingly large number of steps to converge. This is because the gradient does not necessarily points in the general direction of the minimum. For convex problems, we are only guaranteed that the gradient points in the half-space of the minimum - a rather weak guarantee! Many improvements in gradient descent have been devised. We will briefly discuss a small modification that can lead to a substantial increase in performance.\n\n## Steps with memory\n\n$$\n\\Delta \\mathbf{x}^{(k+1)} = \\beta \\Delta \\mathbf{x}^{(k)} - (1-\\beta)\\nabla f(\\mathbf{x}^{(k)})\n$$\n$$\n\\mathbf{x}^{(k+1)} = \\mathbf{x}^{(k)} + t^{(k)}\\Delta \\mathbf{x}^{(k+1)}\\,,\n$$\nwith $\\beta\\in[0,1)$ called the *momentum parameter*.\n\n## Gradient descent algorithm with momentum\n\n> **given** a starting point $\\mathbf{x}$,  $\\beta\\in[0,1)$\n>\n> **initialize** $\\Delta \\mathbf{x}= \\mathbf{0}$\n>\n> **repeat**\n>> 1. *Descent direction*. $\\Delta \\mathbf{x} := \\beta \\Delta \\mathbf{x}- (1-\\beta)(P\\mathbf{x}+\\mathbf{q})$\n>> 2. *Line search*. Choose optimal $t>0$.\n>> 3. *Update*. $\\mathbf{x}:=\\mathbf{x} + t \\Delta \\mathbf{x}$.\n>\n> **until** stopping criterion is reached.\n>\n> **Output** $\\mathbf{x}$"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "P = [1 0; 0 10]\nq = [0, 0]\nr = 0\nx₀ = [10.0, 1.0]\n\n# without momentum\ngdtracker = PathTrack(x₀)\nxstar = Quadratic.gradient_descent(P, q, copy(x₀), tracker=gdtracker)\n\n# with momentum\ngdmtracker = PathTrack(x₀)\nxstar = Quadratic.gradient_descent(P, q, copy(x₀), β=0.4, tracker=gdmtracker)\n\np1 = plotobj(x -> fquad(x, P, q, r), gdtracker, yscale=:log10, label=\"GD\",\n    ylabel=\"f(x) - f(x*)\");\nplotobj!(x -> fquad(x, P, q, r), gdmtracker, label=\"GDM\")\np2 = plot_quadratic(P, q, r, (-10, 10), (-5, 5));\npath!(gdtracker, label=\"GD\");\npath!(gdmtracker, label=\"GDM\", color=mygreen)\nplot(p1, p2)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Illustration of momentum\n\n**Assignment 5**\n\n1. Complete the code for gradient descent with momentum. Use it find the solution for the above system, also starting at $\\mathbf{x}=[0,0]^\\top$. Set $\\beta=0.1$. Do you see an improvement?\n2. Compare both algorithms for minimizing the following system:\n$$\nf(\\mathbf{x}) = \\frac{1}{2}\\mathbf{x}^\\top\\begin{bmatrix}500 & 2 \\\\ 2 & 1\\end{bmatrix}\\mathbf{x} + \\begin{bmatrix}-40 \\\\100 \\end{bmatrix}^\\top\\mathbf{x} -5\\,,\n$$\n\nat $\\mathbf{x}_0= [0, 0]^\\top$. Does momentum increase the speed now?"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "\"\"\"\n    gradient_descent(P::AbstractArray, q::AbstractVector,\n            x₀::AbstractVector; β::Real=0.0, ϵ::Real=1e-6,\n            tracker::Tracker=notrack)\n\nComputes the minimizes of a quadratic system using gradient descent. Optionally\nprovide momentum.\n\nInputs:\n    - P, q: the terms of the nD quadratic system\n    - x₀: starting point\n    - ϵ: convergence parameter\n    - β: momentum parameter\n    - tracker: object of the type `Tracker` to save the steps\n\nOutputs:\n    - xstar: the found minimum\n\"\"\"\nfunction gradient_descent(P::AbstractArray, q::AbstractVector,\n            x₀::AbstractVector; β::Real=0.0, ϵ::Real=1e-6,\n            tracker::Tracker=notrack)\n    @assert 0 ≤ β < 0\n    x = x₀  # initial value\n    Δx = zero(x)  # pre-allocate a vector for the gradient\n    while true\n        Δx .= ...\n        if ...\n            break\n        end\n        # determine stepsize using exact line search\n        t = quadratic_ls(P, q, Δx, x)\n        # perform step\n        x .+= ...\n        trace(tracker, x)  # saves the steps\n    end\n    return x\nend"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conjugated gradient descent\n\nConjugated gradient descent is an important method for approximately minimizing quadratic systems. It converges much faster than simple gradient descent and does not have a hyperparameter as with momentum updates.\n\nThe main idea is that in every step the current search direction and all previous search directions are conjugate with respect to $P$, i.e.\n\n$$\n(\\Delta\\mathbf{x}^{(k)})^\\top  P\\Delta\\mathbf{x}^{(l)}=0 \\quad\\forall  k> l\\,.\n$$\n\n- The search directions can be computed \\alert{without} storing the previous directions.\n- Solves an $n$-dimensional quadratic system exactly in $n$ steps (provided there are no numerical errors).\n- Convergence is\n$$\n|\\mathbf{e}^{(k)}|_P \\le \\left(\\frac{\\kappa -1}{\\kappa + 1} \\right)^k|\\mathbf{e}^{(0)}|_P\\,\n$$\nwith $|\\mathbf{e}^{(k)}|_P = (\\mathbf{x}^\\star - \\mathbf{x}^{(k)})^\\top P (\\mathbf{x}^\\star - \\mathbf{x}^{(k)})$.\n\nThe interested reader is referred to '[An Introduction to the Conjugate Gradient Method Without the Agonizing Pain](http://www.cs.cmu.edu/~quake-papers/painless-conjugate-gradient.pdf)' by Jonathan Richard Shewchuk for an in-depth overview.\n\n# Exercise: signal recovery\n\nAs a practical example of minimizing quadratic systems, let us consider a simple signal recovery problem. Consider an $n$-dimensional real vector $\\mathbf{x}=[x_1,\\ldots,x_n]^\\top$. Rather than observing this vector directly, we have $m$ noisy measurements at random indices (indices drawn randomly with replacement from $\\{1,\\ldots,n\\}$): $\\mathcal{O} = \\{(i_j, y_j)\\mid j=1,\\ldots,m\\}$. These measurements are stored in an $m$-dimensional vector $\\mathbf{y}$. Can we recover $\\mathbf{x}$ from $\\mathbf{y}$?"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "import STMO.Quadratic.SignalRecovery: signalfun, generate_noisy_measurements, make_connection_matrix, make_bookkeeping\n\nn, m = 1000, 100\ny, ind = generate_noisy_measurements(m, n);\nplot(x -> signalfun(x, n), 1:n, label=\" x_i \", color=myblue,\n            xlabel=\" j \", ylabel=\"value\", lw=2)\nscatter!(ind, y, color=myorange, label=\" y_j\")"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "If $m<n$, then we do not have a single measurement for every element of $\\mathbf{x}$. Even if $m>n$, it is likely that some elements of $\\mathbf{x}$ are not observed due to chance (for large $n$, if $n=m$, then about 37% of the elements will not be sampled). Recovering $\\mathbf{x}$ from $\\mathbf{y}$ is an impossible assumption if we do not make some assumptions, this seems an impossible problem in general.\n\nIf we assume that the different values of $\\mathbf{x}$ are on a line, then we can make a *smoothness* assumption: elements of $\\mathbf{x}$ for which the indices are close, likely will have similar values. This idea is expressed in the following minimization problem:\n$$\n\\min_\\mathbf{x}\\, \\frac{1}{2}\\sum_{(i_j, y_j)\\in \\mathcal{O}}(y_j-{x}_{i_j})^2 + \\frac{C}{2} \\mathbf{x}^\\top K^{-1}\\mathbf{x}\\,,\n$$\nwith $K^{-1}$ an inverse kernel (or covariance matrix) and $C$ a tuning hyperparameter. The matrix $K^{-1}$ encodes how the different elements of $\\mathbf{x}$ are related, constructing such a matrix is a topic in machine learning (see course Predictive Modelling). For our purposes, we have chosen this matrix as such that elements should have values closes to each other. Hence, the minimization problem has two terms:\n\n- a data-fitting term to make sure that the recovered vector $\\mathbf{x}$ matches the observations,\n- a regularization term to ensure the smoothness of the solution.\n\nThe parameter $C$ determines the trade-off between the two terms. See below for the heatmap of $K$."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "K, Kinv = make_connection_matrix(n)\n\nheatmap(log10.(K), title=\"Heatmap of K\")"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "The problem can written purely in matrix notation by using the $(m\\times n)$ *bookkeeping matrix* $R$ for which $R_{ij}=1$ if the the $j$-th element of $\\mathbf{y}$ corresponds to the $i$-th element of $\\mathbf{x}$ and $R_{ij}=0$ otherwise. Hence, the compact matrix form is:\n\n$$\n\\min_\\mathbf{x}\\, \\frac{1}{2}(\\mathbf{y}-R\\mathbf{x})^\\top(\\mathbf{y}-R\\mathbf{x}) + \\frac{C}{2} \\mathbf{x}^\\top K^{-1}\\mathbf{x}\\,.\n$$\n\n\n**Assignments**\n\n1. Write the minimization problem in the standard form.\n2. Use the function `generate_noisy_measurements` to generate $m=100$ noisy measurements (standard deviation is 1, default) of a vector with dimensionality $n=1000$. Use the functions `make_connection_matrix` and `make_bookkeeping` to generate the associated matrices $K^{-1}$ and $R$.\n3. Use $C=1$, generate $\\mathbf{x}^\\star$ using the closed-form solution, using gradient descent and gradient descent with momentum. How many steps do the two descent methods need to converge? Use a vector of zeros as the initial point.\n4. Minimize the system for values of $C=1\\times 10^{-2}, 1\\times 10^{-1}, 1, 10, 100$.  Use for momentum $\\beta=0, 0.1, 0.2,\\ldots, 0.9$. Make a table of the number of steps needed to reach convergence for the different values of $C$ and $\\beta$. Make a plot with the different $\\mathbf{x^\\star}$ for different values of $C$. Note that the result should be (nearly) the same whether you use momentum or not, only the number of steps will differ."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# References\n\n- Boyd, S. and Vandenberghe, L., '*[Convex Optimization](https://web.stanford.edu/~boyd/cvxbook/bv_cvxbook.pdf)*'. Cambridge University Press (2004)\n- Goh, G. '[*Why Momentum really works*](https://distill.pub/2017/momentum/)' (2017)"
      ],
      "metadata": {}
    }
  ],
  "nbformat_minor": 2,
  "metadata": {
    "language_info": {
      "file_extension": ".jl",
      "mimetype": "application/julia",
      "name": "julia",
      "version": "1.6.1"
    },
    "kernelspec": {
      "name": "julia-1.6",
      "display_name": "Julia 1.6.1",
      "language": "julia"
    }
  },
  "nbformat": 4
}
